{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 0) Imports & paths\n",
    "# =========================\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.width\", 160)\n",
    "\n",
    "YIELD_PATH = \"../raw_data/barley_yield_from_1982.csv\"\n",
    "CLIMATE_PATH = \"../raw_data/climate_data_from_1982.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 1) Load correctly (IMPORTANT)\n",
    "# =========================\n",
    "# Your CSV is ; separated -> sep=\";\"\n",
    "df_yield = pd.read_csv(YIELD_PATH, sep=\";\")\n",
    "\n",
    "df_climate = pd.read_parquet(CLIMATE_PATH)\n",
    "\n",
    "print(\"df_yield:\", df_yield.shape)\n",
    "print(\"df_climate:\", df_climate.shape)\n",
    "\n",
    "display(df_yield.head())\n",
    "display(df_climate.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 2) Utility functions (EDA helpers)\n",
    "# =========================\n",
    "def clean_cols(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Clean column names.\"\"\"\n",
    "    df = df.copy()\n",
    "    df.columns = (\n",
    "        df.columns.astype(str)\n",
    "        .str.strip()\n",
    "        .str.lower()\n",
    "        .str.replace(r\"\\s+\", \"_\", regex=True)\n",
    "        .str.replace(r\"[^a-z0-9_]\", \"\", regex=True)\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def overview(df: pd.DataFrame, name: str):\n",
    "    \"\"\"Print an overview of the DataFrame.\"\"\"\n",
    "    print(f\"\\n{'=' * 90}\\n{name}\\n{'=' * 90}\")\n",
    "    print(\"shape:\", df.shape)\n",
    "    display(df.head(5))\n",
    "\n",
    "    print(\"\\n--- dtypes ---\")\n",
    "    # FIX: make dtypes sortable by converting to string\n",
    "    dtypes_sorted = df.dtypes.astype(str).sort_values()\n",
    "    display(dtypes_sorted.to_frame(\"dtype\"))\n",
    "\n",
    "    print(\"\\n--- missing (% top 25) ---\")\n",
    "    miss = (df.isna().mean().sort_values(ascending=False) * 100).head(25)\n",
    "    display(miss.to_frame(\"% missing\"))\n",
    "\n",
    "    print(\"\\n--- duplicates ---\")\n",
    "    print(\"duplicate rows:\", df.duplicated().sum())\n",
    "\n",
    "\n",
    "def numeric_stats(df: pd.DataFrame, name: str):\n",
    "    \"\"\"Calculate and display statistics for numeric columns.\"\"\"\n",
    "    num = df.select_dtypes(include=[np.number])\n",
    "    print(f\"\\n{name} - numeric columns:\", list(num.columns))\n",
    "    if num.shape[1] == 0:\n",
    "        return\n",
    "    display(num.describe().T)\n",
    "\n",
    "\n",
    "def categorical_stats(df: pd.DataFrame, name: str, topk=15, max_cols=8):\n",
    "    \"\"\"Calculate and display statistics for categorical columns.\"\"\"\n",
    "    cat_cols = df.select_dtypes(\n",
    "        include=[\"object\", \"string\", \"category\", \"bool\"]\n",
    "    ).columns.tolist()\n",
    "    print(f\"\\n{name} - categorical columns:\", cat_cols)\n",
    "    if not cat_cols:\n",
    "        return\n",
    "    card = df[cat_cols].nunique(dropna=True).sort_values(ascending=False)\n",
    "    display(card.to_frame(\"n_unique\"))\n",
    "\n",
    "    for c in card.head(min(max_cols, len(card))).index:\n",
    "        print(f\"\\nTop values for '{c}'\")\n",
    "        display(df[c].value_counts(dropna=False).head(topk).to_frame(\"count\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 3) Clean column names + basic overview\n",
    "# =========================\n",
    "df_yield = clean_cols(df_yield)\n",
    "df_climate = clean_cols(df_climate)\n",
    "\n",
    "overview(df_yield, \"df_yield\")\n",
    "overview(df_climate, \"df_climate\")\n",
    "\n",
    "numeric_stats(df_yield, \"df_yield\")\n",
    "categorical_stats(df_yield, \"df_yield\")\n",
    "\n",
    "# df_climate is huge: we do careful summaries below\n",
    "categorical_stats(df_climate, \"df_climate\", topk=10, max_cols=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 4) df_yield checks\n",
    "# =========================\n",
    "# Common expected columns given your screenshot: department, year, yield, area,\n",
    "# production\n",
    "print(df_yield.columns)\n",
    "\n",
    "# Convert numeric columns safely if needed\n",
    "for c in [\"year\", \"yield\", \"area\", \"production\"]:\n",
    "    if c in df_yield.columns:\n",
    "        df_yield[c] = pd.to_numeric(df_yield[c], errors=\"coerce\")\n",
    "\n",
    "# Basic sanity checks\n",
    "if \"year\" in df_yield.columns:\n",
    "    print(\"Year range:\", df_yield[\"year\"].min(), \"->\", df_yield[\"year\"].max())\n",
    "\n",
    "# Quick plots\n",
    "if \"yield\" in df_yield.columns:\n",
    "    plt.figure()\n",
    "    plt.hist(df_yield[\"yield\"].dropna(), bins=40)\n",
    "    plt.title(\"Yield distribution\")\n",
    "    plt.xlabel(\"yield\")\n",
    "    plt.ylabel(\"count\")\n",
    "    plt.show()\n",
    "\n",
    "# If you have a department column, show top departments by avg yield\n",
    "dep_col = None\n",
    "for c in [\"department\", \"nom_dep\", \"dep\", \"departement\"]:\n",
    "    if c in df_yield.columns:\n",
    "        dep_col = c\n",
    "        break\n",
    "\n",
    "if dep_col and \"yield\" in df_yield.columns:\n",
    "    dep_summary = (\n",
    "        df_yield.groupby(dep_col)[\"yield\"]\n",
    "        .agg(count=\"count\", mean=\"mean\", median=\"median\")\n",
    "        .sort_values(\"mean\", ascending=False)\n",
    "    )\n",
    "    display(dep_summary.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 5) df_climate structure checks\n",
    "# =========================\n",
    "print(df_climate.columns)\n",
    "\n",
    "# Parse time if needed\n",
    "if \"time\" in df_climate.columns and not np.issubdtype(\n",
    "    df_climate[\"time\"].dtype, np.datetime64\n",
    "):\n",
    "    df_climate[\"time\"] = pd.to_datetime(df_climate[\"time\"], errors=\"coerce\")\n",
    "\n",
    "# Key distributions (fast-ish even on large data)\n",
    "for c in [\"scenario\", \"year\", \"metric\"]:\n",
    "    if c in df_climate.columns:\n",
    "        print(f\"\\nValue counts for {c} (top 20):\")\n",
    "        display(df_climate[c].value_counts(dropna=False).head(20).to_frame(\"count\"))\n",
    "\n",
    "# Date range\n",
    "if \"time\" in df_climate.columns:\n",
    "    print(\"\\nTime range:\", df_climate[\"time\"].min(), \"->\", df_climate[\"time\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 6) Missingness & numeric stats\n",
    "# =========================\n",
    "# Full missingness (still ok)\n",
    "miss_cl = df_climate.isna().mean().sort_values(ascending=False) * 100\n",
    "display(miss_cl.head(20).to_frame(\"% missing\"))\n",
    "\n",
    "# Numeric describe on full data (usually ok)\n",
    "numeric_stats(df_climate, \"df_climate\")\n",
    "\n",
    "# For plots: sample (so it's responsive)\n",
    "SAMPLE_N = 300_000  # adjust if too heavy/too light\n",
    "df_climate_s = df_climate.sample(n=min(SAMPLE_N, len(df_climate)), random_state=42)\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(df_climate_s[\"value\"].dropna(), bins=60)\n",
    "plt.title(\"Climate 'value' distribution (sample)\")\n",
    "plt.xlabel(\"value\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 7) Yearly aggregation (key step)\n",
    "# =========================\n",
    "group_cols = [\n",
    "    c\n",
    "    for c in [\"scenario\", \"code_dep\", \"nom_dep\", \"year\", \"metric\"]\n",
    "    if c in df_climate.columns\n",
    "]\n",
    "print(\"Grouping on:\", group_cols)\n",
    "\n",
    "climate_yearly = df_climate.groupby(group_cols, as_index=False)[\"value\"].agg(\n",
    "    n=\"count\",\n",
    "    mean=\"mean\",\n",
    "    std=\"std\",\n",
    "    min=\"min\",\n",
    "    p05=lambda x: x.quantile(0.05),\n",
    "    p50=lambda x: x.quantile(0.50),\n",
    "    p95=lambda x: x.quantile(0.95),\n",
    "    max=\"max\",\n",
    ")\n",
    "\n",
    "print(\"climate_yearly:\", climate_yearly.shape)\n",
    "display(climate_yearly.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 8) Plot: yearly mean by scenario for a chosen metric\n",
    "# =========================\n",
    "# Pick one metric automatically (most frequent)\n",
    "metric_choice = (\n",
    "    df_climate[\"metric\"].value_counts().index[0]\n",
    "    if \"metric\" in df_climate.columns\n",
    "    else None\n",
    ")\n",
    "print(\"Chosen metric:\", metric_choice)\n",
    "\n",
    "if metric_choice:\n",
    "    tmp = climate_yearly[climate_yearly[\"metric\"] == metric_choice].copy()\n",
    "\n",
    "    # choose up to 3 scenarios to plot\n",
    "    if \"scenario\" in tmp.columns:\n",
    "        scenarios = tmp[\"scenario\"].dropna().unique()[:3]\n",
    "    else:\n",
    "        scenarios = [None]\n",
    "\n",
    "    for sc in scenarios:\n",
    "        plot_df = tmp if sc is None else tmp[tmp[\"scenario\"] == sc]\n",
    "\n",
    "        # aggregate across departments to get a national-ish curve\n",
    "        national = plot_df.groupby(\"year\", as_index=False)[\"mean\"].mean()\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(national[\"year\"], national[\"mean\"])\n",
    "        plt.title(\n",
    "            f\"Mean yearly {metric_choice} (avg across deps)\"\n",
    "            + (\"\" if sc is None else f\" â€” {sc}\")\n",
    "        )\n",
    "        plt.xlabel(\"year\")\n",
    "        plt.ylabel(\"mean(value)\")\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "24-data-strat-bcgx (3.13.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
