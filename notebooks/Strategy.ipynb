{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop Yield Prediction Model - Strategy Notebook\n",
    "\n",
    "This notebook implements the strategy for building a historical crop yield prediction model:\n",
    "1. **Get the data right** — Load, clean, harmonize\n",
    "2. **Basic EDA** — Understand data structure and quality\n",
    "3. **Department mismatch check** — Verify yield and climate data alignment\n",
    "4. **Climate missing values & semantics** — Types of missingness, what scenarios/metrics mean, cleaning implications\n",
    "5. **Yield missing values** — Patterns, recoverability, cleaning implications\n",
    "6. **Feature engineering** — Merge yield + climate; aggregate climate (mean, max per metric)\n",
    "7. **Analytical EDA** — Yield trends, climate–yield relationships, seasonal patterns, multicollinearity, geographic structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "YIELD_PATH = \"../raw_data/barley_yield_from_1982.csv\"\n",
    "CLIMATE_PATH = \"../raw_data/climate_data_from_1982.parquet\"\n",
    "\n",
    "# Load yield data (CSV is semicolon-separated)\n",
    "df_yield = pd.read_csv(YIELD_PATH, sep=\";\")\n",
    "\n",
    "# Load climate data\n",
    "df_climate = pd.read_parquet(CLIMATE_PATH)\n",
    "\n",
    "print(\"Yield data:\", df_yield.shape)\n",
    "print(\"Climate data:\", df_climate.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_cols(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Clean column names: lowercase, underscores, alphanumeric only.\"\"\"\n",
    "    df = df.copy()\n",
    "    df.columns = (\n",
    "        df.columns.astype(str)\n",
    "        .str.strip()\n",
    "        .str.lower()\n",
    "        .str.replace(r\"\\s+\", \"_\", regex=True)\n",
    "        .str.replace(r\"[^a-z0-9_]\", \"\", regex=True)\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "df_yield = clean_cols(df_yield)\n",
    "df_climate = clean_cols(df_climate)\n",
    "\n",
    "# Harmonize department column name (yield has 'department', climate has 'nom_dep')\n",
    "df_yield = df_yield.rename(columns={\"department\": \"nom_dep\"})\n",
    "\n",
    "# Ensure numeric types\n",
    "df_yield[\"year\"] = pd.to_numeric(df_yield[\"year\"], errors=\"coerce\")\n",
    "df_yield[\"yield\"] = pd.to_numeric(df_yield[\"yield\"], errors=\"coerce\")\n",
    "\n",
    "print(\"Yield columns:\", df_yield.columns.tolist())\n",
    "print(\"Climate columns:\", df_climate.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"YIELD DATA\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Shape:\", df_yield.shape)\n",
    "print(\"\\nFirst rows:\")\n",
    "display(df_yield.head(10))\n",
    "print(\"\\nDtypes:\")\n",
    "print(df_yield.dtypes)\n",
    "print(\"\\nMissing values (%):\")\n",
    "print((df_yield.isna().mean() * 100).round(2))\n",
    "print(\"\\nNumeric stats:\")\n",
    "display(df_yield.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"CLIMATE DATA\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Shape:\", df_climate.shape)\n",
    "print(\"\\nFirst rows:\")\n",
    "display(df_climate.head(10))\n",
    "print(\"\\nDtypes:\")\n",
    "print(df_climate.dtypes)\n",
    "print(\"\\nMissing values (%):\")\n",
    "print((df_climate.isna().mean() * 100).round(2))\n",
    "print(\"\\nUnique scenarios:\", df_climate[\"scenario\"].unique().tolist())\n",
    "print(\"Unique metrics:\", df_climate[\"metric\"].unique().tolist())\n",
    "print(\"\\nTime range:\", df_climate[\"time\"].min(), \"to\", df_climate[\"time\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Year coverage\n",
    "print(\"Yield year range:\", df_yield[\"year\"].min(), \"-\", df_yield[\"year\"].max())\n",
    "print(\"Climate year range:\", df_climate[\"year\"].min(), \"-\", df_climate[\"year\"].max())\n",
    "print(\n",
    "    \"\\nYield rows with missing yield:\",\n",
    "    df_yield[\"yield\"].isna().sum(),\n",
    "    f\"({df_yield['yield'].isna().mean() * 100:.1f}%)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Department mismatch check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique departments from each dataset\n",
    "# For climate: use historical scenario only (what we'll use for training)\n",
    "clim_historical = df_climate[df_climate[\"scenario\"] == \"historical\"]\n",
    "\n",
    "depts_yield = set(df_yield[\"nom_dep\"].dropna().str.strip().unique())\n",
    "depts_climate = set(clim_historical[\"nom_dep\"].dropna().str.strip().unique())\n",
    "\n",
    "print(\"Unique departments in YIELD:\", len(depts_yield))\n",
    "print(\"Unique departments in CLIMATE (historical):\", len(depts_climate))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Departments in yield but NOT in climate\n",
    "# (will cause missing climate features when joining)\n",
    "in_yield_not_climate = sorted(depts_yield - depts_climate)\n",
    "\n",
    "# Departments in climate but NOT in yield\n",
    "# (less critical - we just won't have yield to predict)\n",
    "in_climate_not_yield = sorted(depts_climate - depts_yield)\n",
    "\n",
    "# Departments in BOTH (the overlap we can use)\n",
    "in_both = sorted(depts_yield & depts_climate)\n",
    "\n",
    "print(\"DEPARTMENT MISMATCH ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nIn BOTH (can join): {len(in_both)} departments\")\n",
    "print(\n",
    "    \"In YIELD only (no climate - will have missing features):\"\n",
    "    f\"{len(in_yield_not_climate)} departments\"\n",
    ")\n",
    "print(\n",
    "    f\"In CLIMATE only (no yield - cannot train):{len(in_climate_not_yield)} departments\"\n",
    ")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if in_yield_not_climate:\n",
    "    print(\"Departments in YIELD but NOT in CLIMATE:\")\n",
    "    print(in_yield_not_climate)\n",
    "    print(\n",
    "        \"\\n--- Impact: yield rows for these departments will have NaN climate features \"\n",
    "        \"when joined ---\"\n",
    "    )\n",
    "else:\n",
    "    print(\"No departments in yield are missing from climate.\\n\")\n",
    "\n",
    "if in_climate_not_yield:\n",
    "    print(\"Departments in CLIMATE but NOT in YIELD:\")\n",
    "    print(in_climate_not_yield)\n",
    "    print(\n",
    "        \"\\n--- Impact: we have climate data but no yield to train on for these\"\n",
    "        \" departments ---\"\n",
    "    )\n",
    "else:\n",
    "    print(\"No departments in climate are missing from yield.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for potential naming differences (e.g. accents, spaces, hyphens)\n",
    "# Compare sorted lists to spot near-matches\n",
    "print(\"Potential naming differences (fuzzy check):\")\n",
    "for dy in in_yield_not_climate:\n",
    "    for dc in in_climate_not_yield:\n",
    "        # Check if similar (e.g. one has underscore, other has space)\n",
    "        if dy.replace(\"_\", \" \").lower() == dc.replace(\"_\", \" \").lower():\n",
    "            print(f\"  Possible match: yield='{dy}' <-> climate='{dc}'\")\n",
    "        elif dy.lower() in dc.lower() or dc.lower() in dy.lower():\n",
    "            print(f\"  Similar: yield='{dy}' | climate='{dc}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary verdict\n",
    "print(\"=\" * 50)\n",
    "print(\"VERDICT: Is there a department mismatch?\")\n",
    "print(\"=\" * 50)\n",
    "if in_yield_not_climate or in_climate_not_yield:\n",
    "    print(\"YES - There IS a department mismatch.\")\n",
    "    if in_yield_not_climate:\n",
    "        n_rows_affected = df_yield[\n",
    "            df_yield[\"nom_dep\"].str.strip().isin(in_yield_not_climate)\n",
    "        ].shape[0]\n",
    "        pct = 100 * n_rows_affected / len(df_yield)\n",
    "        print(\n",
    "            f\"  - {len(in_yield_not_climate)} departments in yield have no climate data\"\n",
    "        )\n",
    "        print(f\"  - This affects {n_rows_affected} yield rows ({pct:.1f}%)\")\n",
    "    if in_climate_not_yield:\n",
    "        print(\n",
    "            f\"  - {len(in_climate_not_yield)} departments in climate have no yield data\"\n",
    "        )\n",
    "    print(\n",
    "        \"\\nRecommendation: Drop yield rows for departments not in climate, \"\n",
    "        \"or create a mapping if names differ.\"\n",
    "    )\n",
    "else:\n",
    "    print(\n",
    "        \"NO - All departments align. Yield and climate can be joined without mismatch.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Climate data: missing values & semantic exploration\n",
    "\n",
    "We distinguish several types of \"missing\" or problematic values in the climate data:\n",
    "1. **Raw missing** — explicit NaN in the data\n",
    "2. **Coverage missing** — data absent for certain (scenario, year) combinations by design\n",
    "3. **Data quality issues** — invalid values (e.g. negative precipitation)\n",
    "4. **Structural missing** — when joining with yield, department mismatch creates NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Raw missing values (explicit NaN)\n",
    "print(\"RAW MISSING VALUES\")\n",
    "print(\"=\" * 50)\n",
    "missing_pct = df_climate.isna().mean() * 100\n",
    "for col in df_climate.columns:\n",
    "    print(f\"  {col}: {missing_pct[col]:.2f}% missing\")\n",
    "print(\"\\nTotal rows with any NaN:\", df_climate.isna().any(axis=1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Coverage missing — year range per scenario (by design)\n",
    "print(\"COVERAGE BY SCENARIO (year range)\")\n",
    "print(\"=\" * 50)\n",
    "for sc in sorted(df_climate[\"scenario\"].unique()):\n",
    "    sub = df_climate[df_climate[\"scenario\"] == sc]\n",
    "    y_min, y_max = sub[\"year\"].min(), sub[\"year\"].max()\n",
    "    n_rows = len(sub)\n",
    "    print(f\"  {sc:15s}: {y_min}-{y_max}  ({n_rows:,} rows)\")\n",
    "print(\"\\n→ historical = past observations (for training)\")\n",
    "print(\"→ ssp* = future projections (for prediction); no overlap with historical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Data quality issues — invalid values per metric\n",
    "print(\"DATA QUALITY BY METRIC\")\n",
    "print(\"=\" * 50)\n",
    "for m in df_climate[\"metric\"].unique():\n",
    "    vals = df_climate[df_climate[\"metric\"] == m][\"value\"]\n",
    "    n_neg = (vals < 0).sum()\n",
    "    n_inf = np.isinf(vals).sum()\n",
    "    print(f\"\\n  {m}:\")\n",
    "    print(f\"    Negative values: {n_neg:,} ({100 * n_neg / len(vals):.2f}%)\")\n",
    "    print(f\"    Inf values: {n_inf}\")\n",
    "    if n_neg > 0:\n",
    "        print(f\"    Sample negative: {vals[vals < 0].head(3).tolist()}\")\n",
    "print(\n",
    "    \"\\n→ Precipitation: negative values are numerical noise (~1e-25); clip to 0 when \"\n",
    "    \"aggregating.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Structural missing — from department mismatch (recap)\n",
    "print(\"STRUCTURAL MISSING (when joining yield + climate)\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"  Yield departments: {len(depts_yield)}\")\n",
    "print(f\"  Climate departments (historical): {len(depts_climate)}\")\n",
    "print(\n",
    "    f\"  In yield but NOT in climate: {len(in_yield_not_climate)} → yield rows get NaN\"\n",
    "    \"climate features\"\n",
    ")\n",
    "print(\n",
    "    \"  Affected yield rows:\"\n",
    "    f\"{df_yield[df_yield['nom_dep'].str.strip().isin(in_yield_not_climate)].shape[0]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Completeness — expected ~365 days per (scenario, department, year, metric)\n",
    "days_per_group = df_climate.groupby([\"scenario\", \"nom_dep\", \"year\", \"metric\"]).size()\n",
    "print(\"DAYS PER (scenario, department, year, metric)\")\n",
    "print(\"=\" * 50)\n",
    "print(days_per_group.describe())\n",
    "incomplete = (days_per_group < 365).sum()\n",
    "print(f\"\\nIncomplete years (< 365 days): {incomplete}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Summary: what the climate data means & data cleaning implications\n",
    "\n",
    "#### Scenarios (IPCC Shared Socioeconomic Pathways)\n",
    "\n",
    "| Scenario | Meaning | Year range | Use |\n",
    "|----------|---------|------------|-----|\n",
    "| **historical** | Observed/reanalysis climate data | 1982–2014 | **Training** — fit the yield model on past data |\n",
    "| **ssp1_2_6** | Low emissions (\"Taking the Green Road\") — sustainability pathway | 2015–2050 | **Prediction** — optimistic future |\n",
    "| **ssp2_4_5** | Intermediate emissions (\"Middle of the Road\") | 2015–2050 | **Prediction** — moderate future |\n",
    "| **ssp5_8_5** | Very high emissions (fossil-fueled development) | 2015–2050 | **Prediction** — worst-case warming |\n",
    "\n",
    "The numbers (2.6, 4.5, 8.5) are radiative forcing in W/m² by 2100 — higher = more warming.\n",
    "\n",
    "#### Metrics\n",
    "\n",
    "| Metric | Meaning | Units | Notes |\n",
    "|--------|---------|-------|-------|\n",
    "| **near_surface_air_temperature** | Mean daily air temperature at 2 m | Kelvin (K) | Convert to °C: subtract 273.15 |\n",
    "| **daily_maximum_near_surface_air_temperature** | Daily max temperature at 2 m | Kelvin (K) | Useful for heat stress |\n",
    "| **precipitation** | Daily precipitation (rain + snow) | m/day (likely) | Negative values = numerical noise → clip to 0 |\n",
    "\n",
    "#### Data cleaning implications\n",
    "\n",
    "1. **Raw missing**: None — no explicit NaN in climate data.\n",
    "2. **Coverage**: Use `historical` for training (1982–2014); use `ssp*` for future predictions (2015–2050). No overlap.\n",
    "3. **Precipitation**: Clip negative values to 0 before aggregating (sum, mean, etc.).\n",
    "4. **Department mismatch**: Drop yield rows for the 8 departments not in climate, or accept ~15% NaN in joined features and handle in modeling (e.g. drop or impute)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Yield data: missing values analysis\n",
    "\n",
    "Analysis of missing values in the yield dataset — critical for modeling since **yield** is the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Raw missing values per column\n",
    "print(\"YIELD DATA — MISSING VALUES PER COLUMN\")\n",
    "print(\"=\" * 50)\n",
    "missing = df_yield.isna().mean() * 100\n",
    "for col in df_yield.columns:\n",
    "    n = df_yield[col].isna().sum()\n",
    "    print(f\"  {col:15s}: {missing[col]:5.2f}%  ({n:,} rows)\")\n",
    "print(\n",
    "    \"\\n→ yield is the TARGET — missing yield = rows we cannot use for \"\n",
    "    \"supervised learning\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Overlap: do yield, area, production miss together?\n",
    "miss_yield = df_yield[\"yield\"].isna()\n",
    "miss_area = df_yield[\"area\"].isna()\n",
    "miss_prod = df_yield[\"production\"].isna()\n",
    "\n",
    "print(\"OVERLAP OF MISSING VALUES\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"  yield missing AND area missing:    {(miss_yield & miss_area).sum()}\")\n",
    "print(f\"  yield missing AND production missing: {(miss_yield & miss_prod).sum()}\")\n",
    "print(f\"  yield missing but area present:   {(miss_yield & ~miss_area).sum()}\")\n",
    "print(f\"  yield missing but production present: {(miss_yield & ~miss_prod).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Recoverability: yield = production / area (when both present and area > 0)\n",
    "yield_computed = df_yield[\"production\"] / df_yield[\"area\"]\n",
    "recoverable = miss_yield & ~yield_computed.isna() & (df_yield[\"area\"] > 0)\n",
    "\n",
    "print(\"RECOVERABILITY OF MISSING YIELD\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"  Rows with missing yield: {miss_yield.sum()}\")\n",
    "print(f\"  Recoverable from production/area: {recoverable.sum()}\")\n",
    "print(\n",
    "    f\"  Not recoverable (area or production also missing):\"\n",
    "    f\"{miss_yield.sum() - recoverable.sum()}\"\n",
    ")\n",
    "print(\n",
    "    \"\\n→ Consider imputing yield = production/area for recoverable rows before \"\n",
    "    \"dropping.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Missing yield by year — is it systematic?\n",
    "miss_by_year = df_yield.groupby(\"year\")[\"yield\"].apply(lambda x: x.isna().sum())\n",
    "years_with_miss = miss_by_year[miss_by_year > 0]\n",
    "\n",
    "print(\"MISSING YIELD BY YEAR\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Years with any missing yield:\")\n",
    "display(years_with_miss.to_frame(\"n_missing\"))\n",
    "print(\n",
    "    \"\\n→ Missing is spread across all years (1982-2018),\"\n",
    "    \"not concentrated in specific periods.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Missing yield by department — which departments have most missing?\n",
    "miss_by_dep = df_yield.groupby(\"nom_dep\")[\"yield\"].apply(lambda x: x.isna().sum())\n",
    "dep_miss = miss_by_dep[miss_by_dep > 0].sort_values(ascending=False)\n",
    "\n",
    "print(\"DEPARTMENTS WITH MOST MISSING YIELD\")\n",
    "print(\"=\" * 50)\n",
    "display(dep_miss.to_frame(\"n_missing\"))\n",
    "print(\n",
    "    \"\\n→ Urban/Île-de-France departments (Paris, Hauts-de-Seine, etc.) have many\"\n",
    "    \" missing - little barley production.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Summary: yield data missing values & cleaning implications\n",
    "\n",
    "| Column | % missing | Notes |\n",
    "|--------|-----------|-------|\n",
    "| **yield** | ~7% | Target variable — rows with missing yield cannot be used for supervised learning |\n",
    "| **area** | ~3% | Can be used as a feature; overlap with yield missing |\n",
    "| **production** | ~3% | Can be used to recover yield when area is present (yield = production/area) |\n",
    "\n",
    "**Patterns:**\n",
    "- Missing yield is **spread across all years** (1982–2018) — not MNAR in time\n",
    "- **Concentrated in certain departments** (Paris, Hauts-de-Seine, Seine-Saint-Denis, etc.) — urban areas with little barley; likely **Missing Not At Random (MNAR)** for these\n",
    "- **~125 rows** with missing yield can be **recovered** by computing yield = production / area\n",
    "\n",
    "**Recommendations:**\n",
    "1. **Recover** yield where possible: fill `yield = production / area` when yield is NaN but area and production are present and area > 0.\n",
    "2. **Drop** remaining rows with missing yield for supervised learning (or use imputation if needed).\n",
    "3. **Consider** dropping departments with very high missing rates (e.g. Paris, Hauts-de-Seine) if they add noise — they have minimal barley production."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature engineering\n",
    "\n",
    "Merge yield and climate data ourselves. Basic aggregations: **mean** and **max** per (department, year, metric)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Prepare yield data\n",
    "# Recover yield where possible: yield = production / area\n",
    "yield_recovered = df_yield.copy()\n",
    "mask_miss = (\n",
    "    yield_recovered[\"yield\"].isna()\n",
    "    & yield_recovered[\"area\"].notna()\n",
    "    & (yield_recovered[\"area\"] > 0)\n",
    "    & yield_recovered[\"production\"].notna()\n",
    ")\n",
    "yield_recovered.loc[mask_miss, \"yield\"] = (\n",
    "    yield_recovered.loc[mask_miss, \"production\"]\n",
    "    / yield_recovered.loc[mask_miss, \"area\"]\n",
    ")\n",
    "\n",
    "# Keep rows with yield, filter to departments that exist in climate (historical)\n",
    "depts_climate = set(\n",
    "    df_climate[df_climate[\"scenario\"] == \"historical\"][\"nom_dep\"].str.strip().unique()\n",
    ")\n",
    "yield_clean = yield_recovered[yield_recovered[\"yield\"].notna()].copy()\n",
    "yield_clean[\"nom_dep\"] = yield_clean[\"nom_dep\"].str.strip()\n",
    "yield_clean = yield_clean[yield_clean[\"nom_dep\"].isin(depts_climate)][\n",
    "    [\"nom_dep\", \"year\", \"yield\"]\n",
    "]\n",
    "\n",
    "print(f\"Yield rows (after recover + filter to climate depts): {len(yield_clean)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Aggregate climate: mean and max per (nom_dep, year, metric)\n",
    "clim_hist = df_climate[df_climate[\"scenario\"] == \"historical\"].copy()\n",
    "clim_hist[\"nom_dep\"] = clim_hist[\"nom_dep\"].str.strip()\n",
    "# Clip precipitation negatives to 0\n",
    "clim_hist[\"value\"] = np.where(\n",
    "    clim_hist[\"metric\"] == \"precipitation\",\n",
    "    np.maximum(clim_hist[\"value\"], 0),\n",
    "    clim_hist[\"value\"],\n",
    ")\n",
    "\n",
    "climate_agg = (\n",
    "    clim_hist.groupby([\"nom_dep\", \"year\", \"metric\"])[\"value\"]\n",
    "    .agg(mean=\"mean\", max=\"max\")\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Pivot to wide: one column per metric per aggregation -> metric_mean, metric_max\n",
    "climate_wide = climate_agg.pivot_table(\n",
    "    index=[\"nom_dep\", \"year\"], columns=\"metric\", values=[\"mean\", \"max\"]\n",
    ")\n",
    "climate_wide.columns = [f\"{m}_{a}\" for a, m in climate_wide.columns]\n",
    "climate_wide = climate_wide.reset_index()\n",
    "\n",
    "print(\"Climate features (mean, max per metric):\")\n",
    "print(climate_wide.columns.tolist())\n",
    "print(climate_wide.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Merge yield + climate features\n",
    "model_df = yield_clean.merge(climate_wide, on=[\"nom_dep\", \"year\"], how=\"left\")\n",
    "model_complete = model_df.dropna(\n",
    "    subset=[c for c in model_df.columns if c not in [\"nom_dep\", \"year\", \"yield\"]]\n",
    ")\n",
    "\n",
    "print(f\"model_df: {model_df.shape[0]} rows, {model_df.shape[1]} columns\")\n",
    "print(f\"Complete (no missing climate): {model_complete.shape[0]} rows\")\n",
    "display(model_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Analytical EDA\n",
    "\n",
    "Deeper EDA for modeling: yield trends, climate–yield relationships, seasonal patterns, multicollinearity, and geographic structure. Uses `model_df` from feature engineering above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# model_df and model_complete from feature engineering above\n",
    "feat_cols = [c for c in model_df.columns if c not in [\"nom_dep\", \"year\", \"yield\"]]\n",
    "print(f\"model_df: {model_df.shape[0]} rows | complete: {model_complete.shape[0]} rows\")\n",
    "print(\"Feature columns:\", feat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Yield trends over time — national and per department\n",
    "fig, axes = plt.subplots(2, 1, figsize=(10, 8))\n",
    "\n",
    "# National: mean yield by year\n",
    "national = model_df.groupby(\"year\")[\"yield\"].mean()\n",
    "axes[0].plot(national.index, national.values, \"o-\", color=\"steelblue\", linewidth=2)\n",
    "axes[0].set_title(\"National mean yield over time (all departments)\")\n",
    "axes[0].set_xlabel(\"Year\")\n",
    "axes[0].set_ylabel(\"Yield (t/ha)\")\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Sample departments\n",
    "sample_deps = [\"Ain\", \"Nord\", \"Marne\", \"Eure_et_Loir\", \"Gironde\"]\n",
    "for dep in sample_deps:\n",
    "    sub = model_df[model_df[\"nom_dep\"] == dep]\n",
    "    if len(sub) > 0:\n",
    "        axes[1].plot(sub[\"year\"], sub[\"yield\"], \"o-\", label=dep, alpha=0.8)\n",
    "axes[1].set_title(\"Yield over time — sample departments\")\n",
    "axes[1].set_xlabel(\"Year\")\n",
    "axes[1].set_ylabel(\"Yield (t/ha)\")\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Correlation yield vs year\n",
    "print(f\"Correlation yield ~ year: {model_df['yield'].corr(model_df['year']):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Yield distribution by department — n_obs and variability\n",
    "dep_stats = (\n",
    "    model_df.groupby(\"nom_dep\")[\"yield\"]\n",
    "    .agg(n_obs=\"count\", mean=\"mean\", std=\"std\")\n",
    "    .reset_index()\n",
    ")\n",
    "dep_stats = dep_stats.sort_values(\"n_obs\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "axes[0].barh(dep_stats[\"nom_dep\"], dep_stats[\"n_obs\"], color=\"steelblue\", alpha=0.7)\n",
    "axes[0].set_xlabel(\"Number of observations\")\n",
    "axes[0].set_title(\"Observations per department\")\n",
    "axes[0].set_ylim(-0.5, len(dep_stats) - 0.5)\n",
    "\n",
    "axes[1].scatter(dep_stats[\"mean\"], dep_stats[\"std\"], alpha=0.7)\n",
    "axes[1].set_xlabel(\"Mean yield (t/ha)\")\n",
    "axes[1].set_ylabel(\"Std yield\")\n",
    "axes[1].set_title(\"Yield variability by department\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Departments with few observations (< 20):\", (dep_stats[\"n_obs\"] < 20).sum())\n",
    "print(\"Departments with high variability (std > 1.5):\", (dep_stats[\"std\"] > 1.5).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Climate–yield scatter plots — check for non-linear relationships\n",
    "# Convert temp from Kelvin to °C for interpretability\n",
    "df_plot = model_complete.copy()\n",
    "# Pick 4 key features: temp mean/max, precip mean/max\n",
    "plot_cols = [\n",
    "    c for c in feat_cols if \"near_surface_air_temperature\" in c and \"maximum\" not in c\n",
    "][:2]\n",
    "plot_cols += [c for c in feat_cols if \"precipitation\" in c][:2]\n",
    "if len(plot_cols) < 4:\n",
    "    plot_cols = feat_cols[:4]\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, col in zip(axes, plot_cols, strict=True):\n",
    "    vals = df_plot[col] - 273.15 if \"temperature\" in col else df_plot[col]\n",
    "    ax.scatter(vals, df_plot[\"yield\"], alpha=0.3, s=10)\n",
    "    ax.set_xlabel(col + (\" (°C)\" if \"temperature\" in col else \"\"))\n",
    "    ax.set_ylabel(\"Yield (t/ha)\")\n",
    "    ax.set_title(f\"Yield vs {col}\")\n",
    "    valid = vals.notna()\n",
    "    if valid.sum() > 3:\n",
    "        z = np.polyfit(vals[valid], df_plot.loc[valid, \"yield\"], 2)\n",
    "        p = np.poly1d(z)\n",
    "        x_line = np.linspace(vals.min(), vals.max(), 100)\n",
    "        ax.plot(x_line, p(x_line), \"r-\", linewidth=2, label=\"quadratic fit\")\n",
    "        ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Seasonal patterns — growing (Mar–Jul) vs winter (Oct–Feb)\n",
    "# Build seasonal aggregates from historical climate\n",
    "clim_hist = df_climate[df_climate[\"scenario\"] == \"historical\"].copy()\n",
    "clim_hist[\"month\"] = pd.to_datetime(clim_hist[\"time\"]).dt.month\n",
    "clim_hist.loc[clim_hist[\"metric\"] == \"precipitation\", \"value\"] = np.maximum(\n",
    "    clim_hist.loc[clim_hist[\"metric\"] == \"precipitation\", \"value\"], 0\n",
    ")\n",
    "\n",
    "temp = clim_hist[clim_hist[\"metric\"].str.contains(\"temperature\")]\n",
    "precip = clim_hist[clim_hist[\"metric\"].str.contains(\"precip\")]\n",
    "\n",
    "# Growing: Mar–Jul | Winter: Oct (10), Nov (11), Dec (12), Jan (1), Feb (2)\n",
    "temp_growing = (\n",
    "    temp[temp[\"month\"].between(3, 7)]\n",
    "    .groupby([\"nom_dep\", \"year\"])[\"value\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"value\": \"temp_growing\"})\n",
    ")\n",
    "temp_winter = (\n",
    "    temp[temp[\"month\"].isin([1, 2, 10, 11, 12])]\n",
    "    .groupby([\"nom_dep\", \"year\"])[\"value\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"value\": \"temp_winter\"})\n",
    ")\n",
    "precip_growing = (\n",
    "    precip[precip[\"month\"].between(3, 7)]\n",
    "    .groupby([\"nom_dep\", \"year\"])[\"value\"]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"value\": \"precip_growing\"})\n",
    ")\n",
    "precip_winter = (\n",
    "    precip[precip[\"month\"].isin([1, 2, 10, 11, 12])]\n",
    "    .groupby([\"nom_dep\", \"year\"])[\"value\"]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"value\": \"precip_winter\"})\n",
    ")\n",
    "\n",
    "seasonal = (\n",
    "    temp_growing.merge(temp_winter, on=[\"nom_dep\", \"year\"])\n",
    "    .merge(precip_growing, on=[\"nom_dep\", \"year\"])\n",
    "    .merge(precip_winter, on=[\"nom_dep\", \"year\"])\n",
    ")\n",
    "seasonal_model = model_complete[[\"nom_dep\", \"year\", \"yield\"]].merge(\n",
    "    seasonal, on=[\"nom_dep\", \"year\"], how=\"inner\"\n",
    ")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "axes[0].scatter(\n",
    "    seasonal_model[\"temp_growing\"] - 273.15, seasonal_model[\"yield\"], alpha=0.3, s=10\n",
    ")\n",
    "axes[0].set_xlabel(\"Growing season temp (°C)\")\n",
    "axes[0].set_ylabel(\"Yield\")\n",
    "axes[0].set_title(\"Yield vs growing season (Mar–Jul) temp\")\n",
    "\n",
    "axes[1].scatter(\n",
    "    seasonal_model[\"temp_winter\"] - 273.15, seasonal_model[\"yield\"], alpha=0.3, s=10\n",
    ")\n",
    "axes[1].set_xlabel(\"Winter temp (°C)\")\n",
    "axes[1].set_ylabel(\"Yield\")\n",
    "axes[1].set_title(\"Yield vs winter (Oct–Feb) temp\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\n",
    "    \"Correlation yield ~ temp_growing:\",\n",
    "    seasonal_model[\"yield\"].corr(seasonal_model[\"temp_growing\"]),\n",
    ")\n",
    "print(\n",
    "    \"Correlation yield ~ temp_winter:\",\n",
    "    seasonal_model[\"yield\"].corr(seasonal_model[\"temp_winter\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Correlation heatmap — multicollinearity check\n",
    "num_cols = [\"yield\"] + [c for c in model_complete.columns if c in feat_cols]\n",
    "corr = model_complete[num_cols].corr()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"RdBu_r\", center=0, ax=ax, square=True)\n",
    "ax.set_title(\"Correlation heatmap — features and target\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# High correlations (potential multicollinearity)\n",
    "high_corr = [\n",
    "    (i, j)\n",
    "    for i in corr.columns\n",
    "    for j in corr.columns\n",
    "    if i < j and abs(corr.loc[i, j]) > 0.7\n",
    "]\n",
    "print(\"Pairs with |r| > 0.7:\", high_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Geographic patterns — north vs south France\n",
    "temp_col = (\n",
    "    [c for c in feat_cols if \"temperature\" in c and \"mean\" in c][0]\n",
    "    if feat_cols\n",
    "    else None\n",
    ")\n",
    "dep_codes = df_climate[df_climate[\"scenario\"] == \"historical\"][\n",
    "    [\"nom_dep\", \"code_dep\"]\n",
    "].drop_duplicates()\n",
    "geo_df = model_complete.merge(dep_codes, on=\"nom_dep\", how=\"left\")\n",
    "geo_df[\"code_int\"] = pd.to_numeric(geo_df[\"code_dep\"], errors=\"coerce\")\n",
    "geo_df[\"region\"] = np.where(geo_df[\"code_int\"] < 40, \"North/Center\", \"South\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "if temp_col:\n",
    "    for reg in [\"North/Center\", \"South\"]:\n",
    "        sub = geo_df[geo_df[\"region\"] == reg]\n",
    "        axes[0].scatter(\n",
    "            sub[temp_col] - 273.15, sub[\"yield\"], alpha=0.3, s=10, label=reg\n",
    "        )\n",
    "axes[0].set_xlabel(\"Mean temp (°C)\")\n",
    "axes[0].set_ylabel(\"Yield\")\n",
    "axes[0].set_title(\"Yield vs temp by region\")\n",
    "axes[0].legend()\n",
    "\n",
    "reg_summary = (\n",
    "    geo_df.groupby(\"region\").agg(\n",
    "        mean_yield=(\"yield\", \"mean\"),\n",
    "        mean_temp_c=(temp_col, lambda x: (x - 273.15).mean()),\n",
    "    )\n",
    "    if temp_col\n",
    "    else geo_df.groupby(\"region\")[\"yield\"].mean().to_frame(\"mean_yield\")\n",
    ")\n",
    "reg_summary.plot(kind=\"bar\", ax=axes[1], legend=True)\n",
    "axes[1].set_title(\"Mean yield and temp by region\")\n",
    "axes[1].set_xticklabels(reg_summary.index, rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Summary: what we see in the analytical EDA\n",
    "\n",
    "**Yield trends over time**\n",
    "- Clear **upward trend** in national mean yield (1982–2018) — correlation with year ~+0.35. Reflects agricultural technology improvements (better varieties, inputs, practices).\n",
    "- Individual departments follow similar trends with different levels. **Implication**: Consider adding `year` as a feature or detrending yield before modeling climate effects.\n",
    "\n",
    "**Yield distribution by department**\n",
    "- Departments vary in **number of observations** (some have gaps) and **variability** (std). Urban/small-production departments (Paris, Hauts-de-Seine) have fewer obs and more noise.\n",
    "- **Implication**: Filter to departments with sufficient observations (e.g. n ≥ 20) and/or meaningful production for a cleaner model.\n",
    "\n",
    "**Climate–yield relationships**\n",
    "- **Temperature**: Positive correlation with yield (warmer → higher yield in this range). Quadratic fit suggests possible non-linearity — yield may peak and decline at very high temps (heat stress).\n",
    "- **Precipitation**: Negative correlation — more rain associated with lower yield (waterlogging, disease). Non-linear patterns possible.\n",
    "- **Implication**: Tree-based models (RF, XGBoost) can capture non-linearities; consider polynomial or spline terms for linear models.\n",
    "\n",
    "**Seasonal patterns**\n",
    "- **Growing season (Mar–Jul)** temp correlates with yield (main driver).\n",
    "- **Winter (Oct–Feb)** conditions also matter for winter barley — worth including as features.\n",
    "- **Implication**: Keep both growing-season and winter aggregates in feature engineering.\n",
    "\n",
    "**Multicollinearity**\n",
    "- `temp_mean`, `temp_growing_mean`, `temp_max`, `temp_growing_max` are **highly correlated** (r > 0.7).\n",
    "- **Implication**: Use regularization (Ridge/Lasso) or tree models; avoid redundant temp features; consider PCA or selecting one temp metric per type.\n",
    "\n",
    "**Geographic patterns**\n",
    "- North/Center vs South show different mean yields and temperatures — **regional structure** exists.\n",
    "- **Implication**: Consider department or region as a feature (target encoding) to capture unobserved geographic effects."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
