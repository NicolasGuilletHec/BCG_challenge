{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (2803, 9) | Val: (346, 9) | Test: (187, 9)\n",
      "Best iteration: 1796\n",
      "\n",
      "=== TEST (2017+) ===\n",
      "RMSE: 0.6897566700493316\n",
      "MAE : 0.5710421754969632\n",
      "R2  : 0.6853395372855011\n",
      "Saved predictions to outputs/\n",
      "Saved bundle: outputs/xgb_yield_bundle.joblib\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 1) Split temporel panel\n",
    "# =========================\n",
    "df = model_df.copy()\n",
    "df = df.dropna(subset=[\"yield\"]).copy()\n",
    "\n",
    "if \"scenario\" in df.columns:\n",
    "    df = df[df[\"scenario\"] == \"historical\"].copy()\n",
    "\n",
    "df[\"year\"] = pd.to_numeric(df[\"year\"], errors=\"coerce\").astype(\"Int64\")\n",
    "df = df.dropna(subset=[\"year\"]).copy()\n",
    "df[\"year\"] = df[\"year\"].astype(int)\n",
    "\n",
    "df = df.sort_values([\"nom_dep\", \"year\"]).reset_index(drop=True)\n",
    "\n",
    "TARGET = \"yield\"\n",
    "EXCLUDE_COLS = [TARGET]\n",
    "if \"scenario\" in df.columns:\n",
    "    EXCLUDE_COLS.append(\"scenario\")\n",
    "\n",
    "X = df.drop(columns=EXCLUDE_COLS)\n",
    "y = df[TARGET].astype(float)\n",
    "\n",
    "FEATURE_COLUMNS = X.columns.tolist()\n",
    "\n",
    "train_mask = df[\"year\"] <= 2012\n",
    "val_mask   = (df[\"year\"] >= 2013) & (df[\"year\"] <= 2016)\n",
    "test_mask  = df[\"year\"] >= 2017\n",
    "\n",
    "X_train, y_train = X.loc[train_mask], y.loc[train_mask]\n",
    "X_val,   y_val   = X.loc[val_mask],   y.loc[val_mask]\n",
    "X_test,  y_test  = X.loc[test_mask],  y.loc[test_mask]\n",
    "\n",
    "print(\"Train:\", X_train.shape, \"| Val:\", X_val.shape, \"| Test:\", X_test.shape)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 2) Preprocessing (fit sur TRAIN)\n",
    "# =========================\n",
    "numeric_features = X_train.select_dtypes(include=[\"number\", \"float\", \"int\", \"Int64\"]).columns.tolist()\n",
    "categorical_features = [c for c in X_train.columns if c not in numeric_features]\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", Pipeline([(\"imputer\", SimpleImputer(strategy=\"median\"))]), numeric_features),\n",
    "        (\"cat\", Pipeline([\n",
    "            (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)),\n",
    "        ]), categorical_features),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n",
    "\n",
    "Xtr = preprocess.fit_transform(X_train)\n",
    "Xva = preprocess.transform(X_val)\n",
    "Xte = preprocess.transform(X_test)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 3) XGBoost native training (DMatrix) + early stopping\n",
    "# =========================\n",
    "dtrain = xgb.DMatrix(Xtr, label=y_train.values)\n",
    "dval   = xgb.DMatrix(Xva, label=y_val.values)\n",
    "dtest  = xgb.DMatrix(Xte, label=y_test.values)\n",
    "\n",
    "params = {\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    \"eval_metric\": \"rmse\",\n",
    "    \"eta\": 0.02,           # learning_rate\n",
    "    \"max_depth\": 6,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"lambda\": 1.0,\n",
    "    \"alpha\": 0.0,\n",
    "    \"seed\": 42,\n",
    "}\n",
    "\n",
    "num_boost_round = 5000\n",
    "early_stopping_rounds = 200\n",
    "\n",
    "evals = [(dtrain, \"train\"), (dval, \"val\")]\n",
    "\n",
    "booster = xgb.train(\n",
    "    params=params,\n",
    "    dtrain=dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=evals,\n",
    "    early_stopping_rounds=early_stopping_rounds,\n",
    "    verbose_eval=False,\n",
    ")\n",
    "\n",
    "best_iter = booster.best_iteration\n",
    "print(\"Best iteration:\", best_iter)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 4) Refit final sur TRAIN+VAL avec best_iter+1\n",
    "# =========================\n",
    "X_trainval = pd.concat([X_train, X_val], axis=0)\n",
    "y_trainval = pd.concat([y_train, y_val], axis=0)\n",
    "\n",
    "# Refit preprocess on train+val (recommended)\n",
    "Xtv = preprocess.fit_transform(X_trainval)\n",
    "Xte_final = preprocess.transform(X_test)\n",
    "\n",
    "dtrainval = xgb.DMatrix(Xtv, label=y_trainval.values)\n",
    "dtest2    = xgb.DMatrix(Xte_final, label=y_test.values)\n",
    "\n",
    "booster_final = xgb.train(\n",
    "    params=params,\n",
    "    dtrain=dtrainval,\n",
    "    num_boost_round=int(best_iter) + 1,\n",
    "    evals=[(dtrainval, \"trainval\")],\n",
    "    verbose_eval=False,\n",
    ")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 5) Eval + export preds\n",
    "# =========================\n",
    "def metrics(y_true, y_pred):\n",
    "    rmse = float(np.sqrt(mean_squared_error(y_true, y_pred)))\n",
    "    mae  = float(mean_absolute_error(y_true, y_pred))\n",
    "    r2   = float(r2_score(y_true, y_pred))\n",
    "    return rmse, mae, r2\n",
    "\n",
    "pred_test = booster_final.predict(dtest2)\n",
    "\n",
    "rmse, mae, r2 = metrics(y_test, pred_test)\n",
    "print(\"\\n=== TEST (2017+) ===\")\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"MAE :\", mae)\n",
    "print(\"R2  :\", r2)\n",
    "\n",
    "preds_test = X_test[[\"nom_dep\", \"year\"]].copy()\n",
    "preds_test[\"y_true\"] = y_test.values\n",
    "preds_test[\"y_pred\"] = pred_test\n",
    "\n",
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "preds_test.to_csv(\"outputs/preds_test_2017plus.csv\", index=False)\n",
    "preds_test.to_parquet(\"outputs/preds_test_2017plus.parquet\", index=False)\n",
    "print(\"Saved predictions to outputs/\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 6) Save bundle (preprocess + booster_final)\n",
    "# =========================\n",
    "bundle = {\n",
    "    \"preprocess\": preprocess,\n",
    "    \"booster\": booster_final,\n",
    "    \"feature_columns\": FEATURE_COLUMNS,\n",
    "    \"numeric_features\": numeric_features,\n",
    "    \"categorical_features\": categorical_features,\n",
    "    \"xgb_params\": params,\n",
    "    \"best_iteration\": int(best_iter),\n",
    "}\n",
    "\n",
    "joblib.dump(bundle, \"outputs/xgb_yield_bundle.joblib\")\n",
    "print(\"Saved bundle: outputs/xgb_yield_bundle.joblib\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
